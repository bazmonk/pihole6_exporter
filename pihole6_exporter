#!/usr/bin/env python3

import time
import requests
import urllib3
import argparse
import logging
from datetime import datetime
from prometheus_client.core import GaugeMetricFamily, REGISTRY
from prometheus_client import start_http_server

class PiholeCollector(object):

    def __init__(self, host="localhost", key=None):

        self.using_auth = False
        # Disable if you've actually got a good cert set up.
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        self.host = host

        if key is not None:
            self.using_auth = True
            self.sid = self.get_sid(key)

    def get_sid(self, key):
        auth_url = "https://" + self.host + ":443/api/auth"
        headers = {"accept": "application/json", "content_type": "application/json"}
        json_data = {"password": key}
        req = requests.post(auth_url, verify = False, headers = headers, json = json_data)
        
        reply = req.json()
        return reply['session']['sid']

    def collect(self):

        logging.info("beginning scrape...")

        summary_url = "https://" + self.host + ":443/api/stats/summary"
        if self.using_auth:
            headers = {"accept": "application/json", "sid": self.sid}
        else:
            headers = {"accept": "application/json"}
        req = requests.get(summary_url, verify = False, headers = headers)
        reply = req.json()

        query_types = GaugeMetricFamily("pihole_query_by_type",
                "Count of queries by type (24h)", labels=["query_type"])

        for item in reply["queries"]["types"].items():
            labels = [item[0]]
            value = item[1]
            query_types.add_metric(labels, value)

        yield query_types

        status_types = GaugeMetricFamily("pihole_query_by_status",
                "Count of queries by status over 24h", labels=["query_status"])

        for item in reply["queries"]["status"].items():
            labels = [item[0]]
            value = item[1]
            status_types.add_metric(labels, value)

        yield status_types

        reply_types = GaugeMetricFamily("pihole_query_replies",
                "Count of replies by type over 24h", labels=["reply_type"])

        for item in reply["queries"]["replies"].items():
            labels = [item[0]]
            value = item[1]
            reply_types.add_metric(labels, value)

        yield reply_types

        total_counts = GaugeMetricFamily("pihole_query_count",
                "Query counts by category, 24h", labels=["category"])
        
        total_counts.add_metric(["total"], reply["queries"]["total"])
        total_counts.add_metric(["blocked"], reply["queries"]["blocked"])
        total_counts.add_metric(["unique"], reply["queries"]["unique_domains"])
        total_counts.add_metric(["forwarded"], reply["queries"]["forwarded"])
        total_counts.add_metric(["cached"], reply["queries"]["cached"])

        yield total_counts

        # Yes, I skipped percent_blocked.  We can calculate that in Grafana.
        # Better to not provide data that can be derived from other data.

        clients = GaugeMetricFamily("pihole_client_count",
                "Total/active client counts", labels=["category"])
        
        clients.add_metric(["active"], reply["clients"]["active"])
        clients.add_metric(["total"], reply["clients"]["total"])

        yield clients

        gravity = GaugeMetricFamily("pihole_domains_being_blocked",
                "Number of domains on current blocklist", labels=[])
        
        gravity.add_metric([], reply["gravity"]["domains_being_blocked"])

        yield gravity


        summary_url = "https://" + self.host + ":443/api/stats/upstreams"
        if self.using_auth:
            headers = {"accept": "application/json", "sid": self.sid}
        else:
            headers = {"accept": "application/json"}
        req = requests.get(summary_url, verify = False, headers = headers)

        reply = req.json()
        
        upstreams = GaugeMetricFamily("pihole_query_upstream_count",
                "Total query upstream counts (24h)", labels=["ip", "name", "port"])

        for item in reply["upstreams"]:
            labels = [item["ip"], item["name"], str(item["port"])]
            value = item["count"]
            upstreams.add_metric(labels, value)

        yield upstreams

        now = datetime.now().strftime("%s")
        last_min = int(now) // 60 * 60
        min_before = last_min - 60

        query_url = "https://" + self.host + ":443/api/queries?from=" + str(min_before) + "&until=" + str(last_min)
        if self.using_auth:
            headers = {"accept": "application/json", "sid": self.sid}
        else:
            headers = {"accept": "application/json"}
        req = requests.get(query_url, verify = False, headers = headers)

        reply = req.json()

        type_cnt = {}
        status_cnt = {}
        reply_cnt = {}
        client_cnt = {}

        for q in reply["queries"]:
            type = q["type"]
            status = q["status"]
            replytype = q["reply"]["type"]
            client = q["client"]["ip"]

            if type in type_cnt: type_cnt[type] += 1
            else: type_cnt[type] = 1

            if status in status_cnt: status_cnt[status] += 1
            else: status_cnt[status] = 1

            if replytype in reply_cnt: reply_cnt[replytype] += 1
            else: reply_cnt[replytype] = 1

            if client in client_cnt: client_cnt[client] += 1
            else: client_cnt[client] = 1

        q_type = GaugeMetricFamily("pihole_query_type_1m", "Count of query types (last whole 1m)",
                                   labels=["query_type"])
        for t in type_cnt.items():
            q_type.add_metric([t[0]], t[1], last_min)

        yield q_type

        q_status = GaugeMetricFamily("pihole_query_status_1m", "Count of query status (last whole 1m)",
                                   labels=["query_status"])
        for s in status_cnt.items():
            q_status.add_metric([s[0]], s[1], last_min)

        yield q_status

        q_reply = GaugeMetricFamily("pihole_query_reply_1m", "Count of query reply types (last whole 1m)",
                                   labels=["query_reply"])
        for r in reply_cnt.items():
            q_reply.add_metric([r[0]], r[1], last_min)

        yield q_reply

        q_client = GaugeMetricFamily("pihole_query_client_1m", "Count of query clients (last whole 1m)",
                                   labels=["query_client"])
        for c in client_cnt.items():
            q_client.add_metric([c[0]], c[1], last_min)

        yield q_client

        logging.info("scrape completed")
        

if __name__ == '__main__':
    
    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)

    parser = argparse.ArgumentParser(description="Prometheus exporter for Pi-hole version 6+")

    parser.add_argument("-H", "--host", dest="host", type=str, required=False, help="hostname/ip of pihole instance (default localhost)", default="localhost")
    parser.add_argument("-p", "--port", dest="port", type=int, required=False, help="port to expose for scraping (default 9666)", default=9666)
    parser.add_argument("-k", "--key", dest="key", type=str, required=False, help="authentication token (if required)", default=None)

    args = parser.parse_args()

    start_http_server(args.port)
    logging.info("Exporter HTTP endpoint started")

    REGISTRY.register(PiholeCollector(args.host, args.key))
    logging.info("Ready to collect data")
    while True:
        time.sleep(1)

